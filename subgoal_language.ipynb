{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time"
   ],
   "id": "44b264f859e1429e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "llm = LLM(\n",
    "    # model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\",\n",
    "    model=\"google/gemma-3-4b-it\",\n",
    "    dtype=\"bfloat16\",\n",
    "    tensor_parallel_size=1,\n",
    "    gpu_memory_utilization=0.9,\n",
    "    max_model_len=1024\n",
    ")\n",
    "\n",
    "# Configure generation parameters\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    max_tokens=256  # Adjust based on your needs\n",
    ")\n",
    "\n",
    "# # Configure generation parameters\n",
    "# sampling_params = SamplingParams(\n",
    "#     temperature=1.0,\n",
    "#     top_p=0.998,\n",
    "#     max_tokens=256  # Adjust based on your needs\n",
    "# )\n",
    "\n"
   ],
   "id": "a4bd55f97d9b565c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# def wrap_prompt(prompt: str) -> str:\n",
    "#     return f'<｜User｜> {prompt} <｜Assistant｜>'\n",
    "#\n",
    "# with open(\"val_language.json\", \"r\") as f:\n",
    "#     prompts = json.load(f)\n",
    "#\n",
    "#\n",
    "# example1 = \"put green squash into pot or pan\"  #2\n",
    "# example2 = 'Pick the carrot from left side and place it on the orange cloth'  # 3\n",
    "# example3 = 'open the drawer'\n",
    "# example4 = 'uncover the pot and put the lid on the left side of the cloth'\n",
    "#\n",
    "# sentences = list(prompts.values())[:100]\n",
    "#\n",
    "# from collections import deque\n",
    "#\n",
    "# last_words1 = deque(maxlen=5)\n",
    "# last_words2 = deque(maxlen=5)\n",
    "#\n",
    "# for lang, num_sg in sentences:\n",
    "#     system_prompt = (f\"I need to decompose a language command into 2 smaller language commands. \"\n",
    "#                      f\"This language command consists of grasping an object and placing it somewhere. \"\n",
    "#                      f\"Here are some examples.\\n\"\n",
    "#                      f\"Example 1: Decompose '{example1}' into 2 smaller language commands. Output format:\\n\"\n",
    "#                      f\"grasp the green squash.\\n\"\n",
    "#                      f\"place the green squash into the pot or pan.\\n\"\n",
    "#                      f\"Example 2: Decompose '{example2}' into 2 smaller language commands. Output format:\\n\"\n",
    "#                      f\"grab the carrot from the left side.\\n\"\n",
    "#                      f\"place the carrot on the orange cloth.\\n\"\n",
    "#                      f\"Example 3: Decompose '{example3}' into 2 smaller language commands. Output format:\\n\"\n",
    "#                      f\"grasp the drawer handling.\\n\"\n",
    "#                      f\"pull the drawer open.\\n\"\n",
    "#                      f\"Example 4: Decompose '{example4}' into 2 smaller language commands. Output format:\\n\"\n",
    "#                      f\"grab the pot lid.\\n\"\n",
    "#                      f\"put the pot lid on the left side of the cloth.\\n\"\n",
    "#                      f\"Now decompose this language command: '{lang}' into exactly 2 smaller language commands. \"\n",
    "#                      f\"For the first command, DO NOT use any of the following verbs: {list(last_words1)}. \"\n",
    "#                      f\"Remember the first command must be a synonym of grasp. \"\n",
    "#                      f\"For the second command, DO NOT use any of the following verbs: {list(last_words2)}. \"\n",
    "#                      f\"Remember the second command must be a synonym of place or pull. \"\n",
    "#                      f\"IMPORTANT: You must ONLY output the 2 sentences with no additional text, explanations, or thinking process.\")\n",
    "#\n",
    "#     # Approximate\n",
    "#     num_tokens = len(system_prompt.split())\n",
    "#     assert num_tokens < 1024\n",
    "#\n",
    "#     system_prompt = wrap_prompt(system_prompt)\n",
    "#     #\n",
    "#     outputs = llm.generate([system_prompt], sampling_params)\n",
    "#\n",
    "#     # Extract and store the generated text\n",
    "#     generated_text = outputs[0].outputs[0].text[1:]  # for some reason, there's always a space at the beginning\n",
    "#     command1, command2 = generated_text.split('\\n')[:2]\n",
    "#     verb1 = command1.split()[0]\n",
    "#     verb2 = command2.split()[0]\n",
    "#\n",
    "#     last_words1.append(verb1)\n",
    "#     last_words2.append(verb2)\n",
    "#\n",
    "#     print(lang)\n",
    "#     print(command1)\n",
    "#     print(command2)\n",
    "#\n",
    "\n",
    "def wrap_prompt(prompt: str) -> str:\n",
    "    return f'<｜User｜> {prompt} <｜Assistant｜>'\n",
    "\n",
    "with open(\"train_language.json\", \"r\") as f:\n",
    "    prompts = json.load(f)\n",
    "\n",
    "\n",
    "example1 = \"put green squash into pot or pan\"  #2\n",
    "example2 = 'Pick the carrot from left side and place it on the orange cloth'  # 3\n",
    "example3 = 'open the drawer'\n",
    "example4 = 'uncover the pot and put the lid on the left side of the cloth'\n",
    "\n",
    "# If python >= 3.7, the order will match\n",
    "file_names = list(prompts.keys())\n",
    "sentences = list(prompts.values())\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "batch_size = 8\n",
    "last_words1 = deque(maxlen=batch_size)\n",
    "last_words2 = deque(maxlen=batch_size)\n",
    "\n",
    "decomposed_language = {}\n",
    "\n",
    "for i in tqdm(range(0, len(sentences), batch_size)):\n",
    "    fn_batch = file_names[i:i+batch_size]\n",
    "    sentence_batch = sentences[i:i+batch_size]\n",
    "    batch_prompts = []\n",
    "    for lang, _ in sentence_batch:\n",
    "        system_prompt = (f\"I need to decompose a language command into 2 smaller language commands. \"\n",
    "                         f\"This language command consists of grasping an object and placing it somewhere. \"\n",
    "                         f\"Here are some examples.\\n\"\n",
    "                         f\"Example 1: Decompose '{example1}' into 2 smaller language commands. Output format:\\n\"\n",
    "                         f\"grasp the green squash.\\n\"\n",
    "                         f\"place the green squash into the pot or pan.\\n\"\n",
    "                         f\"Example 2: Decompose '{example2}' into 2 smaller language commands. Output format:\\n\"\n",
    "                         f\"grab the carrot from the left side.\\n\"\n",
    "                         f\"place the carrot on the orange cloth.\\n\"\n",
    "                         f\"Example 3: Decompose '{example3}' into 2 smaller language commands. Output format:\\n\"\n",
    "                         f\"grasp the drawer handling.\\n\"\n",
    "                         f\"pull the drawer open.\\n\"\n",
    "                         f\"Example 4: Decompose '{example4}' into 2 smaller language commands. Output format:\\n\"\n",
    "                         f\"grab the pot lid.\\n\"\n",
    "                         f\"put the pot lid on the left side of the cloth.\\n\"\n",
    "                         f\"Now decompose this language command: '{lang}' into exactly 2 smaller language commands. \"\n",
    "                         f\"For the first command, DO NOT use any of the following verbs: {list(last_words1)}. \"\n",
    "                         f\"Remember the first command must be a synonym of grasp. \"\n",
    "                         f\"For the second command, DO NOT use any of the following verbs: {list(last_words2)}. \"\n",
    "                         f\"Remember the second command must be a synonym of place or pull. \"\n",
    "                         f\"IMPORTANT: You must ONLY output the 2 sentences with no additional text, explanations, or thinking process.\")\n",
    "\n",
    "        # Approximate check\n",
    "        num_tokens = len(system_prompt.split())\n",
    "        assert num_tokens < 1024\n",
    "\n",
    "        batch_prompts.append(wrap_prompt(system_prompt))\n",
    "\n",
    "\n",
    "    outputs = llm.generate(batch_prompts, sampling_params)\n",
    "\n",
    "     # Process outputs\n",
    "    for j, (output, fn) in enumerate(zip(outputs, fn_batch)):\n",
    "        generated_text = output.outputs[0].text.strip()\n",
    "        try:\n",
    "            # Extract the commands\n",
    "            command1, command2 = generated_text.split('\\n')[:2]\n",
    "\n",
    "            # Extract verbs\n",
    "            verb1 = command1.split()[0]\n",
    "            verb2 = command2.split()[0]\n",
    "\n",
    "            # Update verb tracking\n",
    "            last_words1.append(verb1)\n",
    "            last_words2.append(verb2)\n",
    "\n",
    "            # Store results\n",
    "            lang, _ = sentence_batch[j]\n",
    "            # print(f\"Original: {lang}\")\n",
    "            # print(f\"Command 1: {command1}\")\n",
    "            # print(f\"Command 2: {command2}\")\n",
    "            # print(\"-\" * 50)\n",
    "\n",
    "            decomposed_language[fn] = {\"original_command\": lang,\n",
    "                                       \"subgoal_commands\": [command1, command2]}\n",
    "\n",
    "            # results.append({\n",
    "            #     \"original\": lang,\n",
    "            #     \"command1\": command1,\n",
    "            #     \"command2\": command2,\n",
    "            #     \"verb1\": verb1,\n",
    "            #     \"verb2\": verb2\n",
    "            # })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing output {j}: {e}\")\n",
    "            print(f\"Raw output: {generated_text}\")\n",
    "            print(\"-\" * 50)\n",
    "            raise e\n",
    "\n",
    "    # print(f\"Processed batch {i//batch_size + 1}/{(len(sentences) + batch_size - 1)//batch_size}\")\n",
    "\n",
    "with open (\"train_decomposed_language.json\", \"w\") as f:\n",
    "    json.dump(decomposed_language, f, indent=4)\n",
    "\n",
    "\n"
   ],
   "id": "9fc4116b1be0132d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "49e1d53e697a6a53",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
